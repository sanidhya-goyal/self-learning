# Designing High Availability Systems

## Goals:

- Ensure **99.9999% uptime** (six nines availability)
- Provide **data resiliency**
- Eliminate **single points of failure**
- Support **disaster recovery**
- Architect for **fault tolerance** and **redundancy**

---

## 1. Single Node Architecture

```
Client → Load Balancer → Microservices (X, Y, Z) → Database
```


- Microservices can scale horizontally.
- However, the **DB becomes a Single Point of Failure (SPOF)**.
- If the **database goes down**, the entire system becomes unavailable.

---

## 2. Multi-Node Architecture

### Types:
- **Active-Passive**
- **Active-Active**

---

## a. Active-Passive Architecture

### Setup:

- **Two Data Centers** (e.g., Mumbai and Pune)
- Load balancer distributes traffic across both data centers.
- Only **one DB is primary (Read-Write)**.
- Other DBs are **read replicas / standby**, also called **Disaster Recovery (DR) centers**.

### Flow:

```
                         +---------+
                         | Client  |
                         +----+----+
                              |
                              v
                     +--------+--------+
                     |   Load Balancer |
                     +--------+--------+
                              |
           +------------------+------------------+
           |                                     |
           v                                     v
   +--------------+                      +--------------+
   |  DataCenter1 |                      |  DataCenter2 |
   +------+-------+                      +------+-------+
          |                                     |
  +-------+--------+                   +--------+-------+
  |   App Node X1  |                   |   App Node X2  |
  +----------------+                   +----------------+
  |   App Node Y1  |                   |   App Node Y2  |
  +----------------+                   +----------------+
  |   App Node Z1  |                   |   App Node Z2  |
  +----------------+                   +----------------+
          |                                     |
          v                                     v
   +--------------+                      +--------------+
   |   Primary DB |                      |  Replica DB  |
   +--------------+                      +--------------+

```
Out of all the data centres, only one can be primary DB / Live DB / Read-Write DB and the other DBs ( in other data centres ) are replicas
These replicas are known as Disaster Recovery data centres


1. Request comes to Data center 1 (POST request)
2. A read request comes, lets say the load balancer serves this from Data center 1, but in case if the load balancers sends the request to Data center 2, the request will move to primary too, the application layer will redirect this Data center 1 DB ( primary db )\
And from here the syncup will happen from primary db to replicas

#### Why can’t we use the replicas?

- Oracle, My Sql, Postgres are not multi master , I.e. they can only write into 1 primary / live DB.
- Whenever any write request comes in, they only needs to transferred to the primary DB.
- But they can read from replicas , (sometimes also called as read only DB).
- Write can happen only on 1 DB, but for read we can redirect to replicas too.
- Assume, Primary db goes down,
The traffic can be switched to Data center 2 (disaster recovery data center) and we will make this to primary.
- Single directional syncup is there from primary to replicas.


### Disadvantages:

- **Latency** due to redirection or cross-DC communication.
- **Downtime** during DB failover.
- Requires **manual/automated orchestration** for DB promotion.

---

## b. Active-Active Architecture

### Setup:

- **Both Data Centers are live** and handle traffic.
- Both databases are **primary**, supporting **Read and Write** operations.
- Requires **bi-directional data sync** between DBs.
- Typically **NoSQL DBs**, e.g., **Cassandra, Couchbase, DynamoDB**
- Support **multi-master** replication.

### Conflict Scenario:

- Write occurs in DC1 and DC2 **at the same time** → Conflict
- Need **conflict resolution** strategies (e.g., LWW - Last Write Wins, custom logic)

### Advantages:

- **Low latency** (users served by nearest DC)
- **High throughput** (both DBs handle requests)
- No single point of failure
- Instant failover — no need to promote a standby

### Disadvantages:

- **Complex replication and conflict resolution**
- Higher **operational overhead**
- Not all use-cases need multi-master writes
---

